{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ideas adopted from:\n",
        "\n",
        "CNN and RNN model : https://www.worldscientific.com/doi/pdf/10.1142/S2196888822500300\n",
        "\n",
        "Limitations: The nature of the audio in the reasearch is different from the audio data that is given to us. Hence, we think that it is not suitable to adopt the CNN and RNN model here because it is too complex, computationally heavy and might not boost our model's accuracy too. \n",
        "\n",
        "How to overcome: We decide to take the trial-and-error approach while designing our CNN and RNN models, starting from the basic layers and slowly adding layers to get a higher accuracy.\n",
        "\n",
        "Feature extraction for audio files: https://www.kaggle.com/code/gopidurgaprasad/mfcc-feature-extraction-from-audio\n",
        "\n",
        "Limitations: The article introduces us what to extract for audio classification but only teaches us how to extract MFCC from a single audio file. But for our implementation, we do not only need to extract MFCCs, but also have to ensure that the number of frames is the same across all audio files.\n",
        "\n",
        "How to overcome: Manually calculate the formula to get different hop lengths for each aduio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOa5wlxiD59g"
      },
      "source": [
        "Code referenced and their respective source:\n",
        "\n",
        "Wrapping using KerasClassifier: https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/\n",
        "\n",
        "Hyperparameter tuning using GridSearchCV: https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/\n",
        "\n",
        "Extracting MFCCs and Mel-spectrogram: https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a lot of functions that serves different purposes. This is to increase code readability and also allows users to run a certain part of code independently.\n",
        "\n",
        "To run the model, scroll to the end of the file and simply uncomment the line that you want to run.\n",
        "\n",
        "Users can experiment different values of parameters, the instructions are documented in the README pdf file. \n",
        "\n",
        "The parameters that can be changed: batch size, num_of_frames, cv (in GridSearchCV) and epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "tl36NXangFOd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display as dsp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV \n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from scikeras.wrappers import KerasClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3kHsjvuO23"
      },
      "source": [
        "Functions to extract mfccs/mel spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WqDBJxSTgim-"
      },
      "outputs": [],
      "source": [
        "def extract_mfccs(audio, sampling_rate, num_mfccs, desired_num_frames):\n",
        "    hop_length = int(audio.size/(desired_num_frames - 1))  # hop_length depends on the length of audio\n",
        "\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=num_mfccs, n_fft=512, hop_length=hop_length)\n",
        "\n",
        "    num_rows = mfccs.shape[0]\n",
        "    num_frames = desired_num_frames\n",
        "\n",
        "    return mfccs, num_rows, num_frames\n",
        "\n",
        "\n",
        "def extract_specs(audio, sampling_rate, desired_num_frames):\n",
        "    hop_length = int(audio.size/(desired_num_frames - 1))  # hop_length depends on the length of audio\n",
        "\n",
        "    specs = librosa.feature.melspectrogram(y=audio, sr=sampling_rate, n_fft=512, hop_length=hop_length)\n",
        "\n",
        "    num_rows = specs.shape[0]\n",
        "    num_frames = desired_num_frames\n",
        "\n",
        "    return specs, num_rows, num_frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb-Q5CJ1uYj6"
      },
      "source": [
        "Loads and extract features (mfccs/mel spectrogram) from audio file.\n",
        "\n",
        "Returns all_data, all_labels, no. of rows and no. of frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Q7zigVvqg52n"
      },
      "outputs": [],
      "source": [
        "def load_data_mfccs(data_dir, sampling_rate, desired_num_frames, num_mfccs):\n",
        "    all_mfccs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for file in os.listdir(data_dir):\n",
        "        if not file.endswith(\".wav\"):  # if the file is invalid, skip\n",
        "            continue\n",
        "\n",
        "        audio, sr = librosa.load(f'{data_dir}{file}', sr=sampling_rate)\n",
        "\n",
        "        '''\n",
        "        Uncomment to display the audio in waveform\n",
        "\n",
        "        plt.figure()\n",
        "        plt.title('Waveform')\n",
        "        dsp.waveshow(audio, axis='s')\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "        mfccs, num_rows, num_frames = extract_mfccs(audio, sampling_rate, num_mfccs, desired_num_frames)\n",
        "\n",
        "        '''\n",
        "        Uncomment to display the mfccs\n",
        "\n",
        "        plt.figure()\n",
        "        plt.title('MFCCs')\n",
        "        dsp.specshow(mfccs, x_axis='s', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "        label = int(file[0])\n",
        "\n",
        "        all_mfccs.append(mfccs)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    all_mfccs = np.array(all_mfccs)\n",
        "    all_mfccs = all_mfccs.transpose(0, 2, 1)  # transpose to fit into CNN and RNN\n",
        "\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return all_mfccs, all_labels, num_rows, num_frames  # num_rows and num_frames are important information for CNN and RNN\n",
        "\n",
        "\n",
        "\n",
        "def load_data_specs(data_dir, sampling_rate, desired_num_frames, *dummy_args): # dummy_args has no use, just to support the higher order functions below\n",
        "    all_specs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for file in os.listdir(data_dir):\n",
        "        if not file.endswith(\".wav\"):\n",
        "            continue\n",
        "\n",
        "        audio, sr = librosa.load(f'{data_dir}{file}', sr=sampling_rate)\n",
        "\n",
        "        '''\n",
        "        Uncomment to display the audio in waveform\n",
        "\n",
        "        plt.figure()\n",
        "        plt.title('Waveform')\n",
        "        dsp.waveshow(audio, axis='s')\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "        specs, num_rows, num_frames = extract_specs(audio, sampling_rate, desired_num_frames)\n",
        "\n",
        "\n",
        "        '''\n",
        "        Uncomment to display the mfccs\n",
        "\n",
        "        specs = librosa.power_to_db(specs, ref=np.max)  # transform into db to make the spectrogram clearer\n",
        "        plt.figure()\n",
        "        plt.title('Mel Spectrogram')\n",
        "        dsp.specshow(specs, x_axis='s', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "        label = int(file[0])\n",
        "\n",
        "        all_specs.append(specs)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    all_specs = np.array(all_specs)\n",
        "    all_specs = all_specs.transpose(0, 2, 1)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    return all_specs, all_labels, num_rows, num_frames\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--3_7OG7u4Z4"
      },
      "source": [
        "A function to get the **CNN** model. (required for KerasClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3U91s817vObO"
      },
      "outputs": [],
      "source": [
        "def get_cnn_model(num_frames, num_rows, filters, kernel_size, pool_size, dense_units, dropout_rate, learning_rate):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(layers.Input(shape=(num_frames, num_rows, 1)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters, kernel_size, activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters, kernel_size, activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    adam = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMtiyteavUPt"
      },
      "source": [
        "A function to get the **RNN** model. (required for KerasClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Rgl_O9Gtvbwc"
      },
      "outputs": [],
      "source": [
        "def get_rnn_model(num_frames, num_rows, units, dropout_rate, learning_rate):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.LSTM(units, input_shape=(num_frames, num_rows)))\n",
        "\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    adam = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhoTaf7vcsP"
      },
      "source": [
        "Main function to run **CNN** (Cross Validation and Hyperparameter Tuning have been included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yMjHS6hrvrwS"
      },
      "outputs": [],
      "source": [
        "def main_cnn(load_data_function):\n",
        "    all_data, all_labels, num_rows, num_frames = load_data_function(\"data/\", 8000, 8, 13) # higher order function, if provided function is load_data_specs, 13 will be ignored\n",
        "                                                                                          # sampling_rate = 8000Hz, num_of_frames = 8, num_of_mfccs = 13\n",
        "\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(all_data, all_labels, train_size = 0.8)\n",
        "\n",
        "    param_grid = {\n",
        "        'filters': [32, 64],\n",
        "        'dense_units': [64, 128],\n",
        "        'dropout_rate': [0.3, 0.5],\n",
        "        'learning_rate': [0.001, 0.005]\n",
        "    }\n",
        "\n",
        "    model = KerasClassifier(model=get_cnn_model, num_frames=num_frames, num_rows=num_rows, filters=32, kernel_size=(3,3),   # wraps the Keras model\n",
        "                            pool_size=(2,2), dense_units=64, dropout_rate=0.1, learning_rate=0.001, epochs=10)\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy') \n",
        "\n",
        "    grid_result = grid_search.fit(train_data, train_labels, batch_size=32) \n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "    best_cnn_model = grid_result.best_estimator_\n",
        "    test_accuracy = best_cnn_model.score(test_data, test_labels) # test the best model and testing data\n",
        "    print(\"Test accuracy: \", test_accuracy)\n",
        "\n",
        "    prediction = best_cnn_model.predict(test_data)              # get classification report\n",
        "    report = classification_report(test_labels, prediction)\n",
        "    print(report)\n",
        "\n",
        "    cm = confusion_matrix(test_labels, prediction)              # get confusion matrix\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "\n",
        "    training_history = best_cnn_model.history_                  # display best model's training history\n",
        "    plt.plot(training_history['accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26XFyuRRvwjv"
      },
      "source": [
        "Main function to run **RNN** (Cross Validation and Hyperparameter Tuning have been included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "BtPu9LbPvx3M"
      },
      "outputs": [],
      "source": [
        "def main_rnn(load_data_function):\n",
        "    all_data, all_labels, num_rows, num_frames = load_data_function(\"data/\", 8000, 10, 13)\n",
        "\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(all_data, all_labels, train_size = 0.8)\n",
        "\n",
        "    param_grid = {\n",
        "        'units': [64, 128],\n",
        "        'dropout_rate': [0.3, 0.5],\n",
        "        'learning_rate': [0.001, 0.005]\n",
        "    }\n",
        "\n",
        "    model = KerasClassifier(model=get_rnn_model, num_rows=num_rows, num_frames=num_frames, units=64, dropout_rate=0.3, learning_rate=0.001, epochs=10)\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "    grid_result = grid_search.fit(train_data, train_labels, batch_size=32)\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "    best_rnn_model = grid_result.best_estimator_\n",
        "    test_accuracy = best_rnn_model.score(test_data, test_labels)\n",
        "    print(\"Test accuracy: \", test_accuracy)\n",
        "\n",
        "    prediction = best_rnn_model.predict(test_data)\n",
        "    report = classification_report(test_labels, prediction)\n",
        "    print(report)\n",
        "\n",
        "    cm = confusion_matrix(test_labels, prediction)\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "\n",
        "    training_history = best_rnn_model.history_\n",
        "    plt.plot(training_history['accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBviDGgVwE_T"
      },
      "source": [
        "Main function to run **KNN** (Cross validation and Hyperparameter Tuning have been included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vQipraFSwMQ0"
      },
      "outputs": [],
      "source": [
        "def main_knn(load_data_function):\n",
        "    all_data, all_labels, num_rows, num_frames = load_data_function(\"data/\", 8000, 8, 13)\n",
        "    all_flattened_data = []\n",
        "\n",
        "    for data in all_data:                           # flatten all 2-D arrays into 1-D arrays\n",
        "        flattened_data = data.flatten()\n",
        "        all_flattened_data.append(flattened_data)\n",
        "\n",
        "    all_flattened_data = np.array(all_flattened_data)\n",
        "\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(all_flattened_data, all_labels, train_size = 0.8, random_state=42)\n",
        "\n",
        "    sqrt_n = int(pow(train_labels.shape[0], 0.5))   # square root of total number of training data\n",
        "\n",
        "    param_grid = {\n",
        "        'n_neighbors' : [5, 15, 25, 35, sqrt_n],\n",
        "        'weights' : ['uniform','distance'],\n",
        "        'metric' : ['minkowski','euclidean', 'manhattan']\n",
        "    }\n",
        "\n",
        "    model = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski')\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "    grid_result = grid_search.fit(train_data, train_labels)\n",
        "    print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "    best_knn_model = grid_result.best_estimator_\n",
        "    test_accuracy = best_knn_model.score(test_data, test_labels)\n",
        "    print(\"Test accuracy: \", test_accuracy)\n",
        "\n",
        "    prediction = best_knn_model.predict(test_data)\n",
        "    report = classification_report(test_labels, prediction)\n",
        "    print(report)\n",
        "\n",
        "    cm = confusion_matrix(test_labels, prediction)\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "    cm_display.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hROjEfkPwyDh"
      },
      "source": [
        "\n",
        "6 combinations: main_cnn/main_rnn/main_knn + load_data_mfccs/load_data_specs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1kWISgYpwxqB"
      },
      "outputs": [],
      "source": [
        "## Uncomment any functions below\n",
        "\n",
        "## main_cnn(load_data_mfccs)\n",
        "## main_rnn(load_data_mfccs)\n",
        "## main_knn(load_data_mfccs)\n",
        "\n",
        "## main_cnn(load_data_specs)\n",
        "## main_rnn(load_data_specs)\n",
        "## main_knn(load_data_specs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
